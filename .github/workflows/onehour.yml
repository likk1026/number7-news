name: Run All Crawlers Every 1 Hour

on:
  schedule:
    - cron: '0 * * * *'  # æ¯ 1 å°æ™‚åŸ·è¡Œä¸€æ¬¡ (æ•´é»)
  workflow_dispatch:  # å…è¨±æ‰‹å‹•è§¸ç™¼

jobs:
  run_crawlers:
    runs-on: ubuntu-latest

    services:
      mysql:
        image: mysql:5.7
        env:
          MYSQL_ROOT_PASSWORD: 1234567890
          MYSQL_DATABASE: allnews
          MYSQL_USER: myuser
          MYSQL_PASSWORD: 1234567890

        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping --host=localhost --user=root --password=rootpassword" --health-interval=10s --health-timeout=5s --health-retries=3


    steps:
      - name: ğŸ”„ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install -r requirements.txt

      - name: ğŸ•· Run All Python Scripts in news_onehour
        run: |
          for script in news_onehour/*.py; do
            echo "Running $script..."
            python "$script"
          done
